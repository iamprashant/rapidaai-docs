---
title: "Deployment Options"
description: "Understanding how to deploy the Rapida Voice AI Platform"
sidebarTitle: "Deployment Options"
icon: "server"
---

## Overview

The Rapida Voice AI Platform provides multiple deployment options to run your voice AI agents in production environments. Understanding these options helps you make the right choice for your specific use case.

Rapida Voice AI Platform supports two primary deployment modes:

- **Rapida Managed**: Fully managed platform service hosted on cloud infrastructure
- **Self-Hosting**: Self-managed deployment on your own infrastructure (EC2, Docker Kubernetes, etc.)

## Rapida Managed

Rapida Managed is the quickest way to get started with deployment, scaling, and maintenance of your AI agents. When you use Rapida Managed:

- **Zero Infrastructure Management**: No need to manage servers, containers, or scaling
- **Automatic Scaling**: Built-in load balancing and auto-scaling capabilities
- **High Reliability**: Enterprise infrastructure with automatic failover
- **Managed Updates**: Automatic security patches and feature upgrades
- **Regional Deployment**: Choose from multiple global regions to optimize latency
- **Built-in Monitoring**: Integrated metrics, logging, and health monitoring

Best for: Teams that want to focus on agent development rather than infrastructure management.

## Self-Hosting (EC2, Docker, or Custom Infrastructure)

Self-hosting gives you complete control over your deployment environment and infrastructure. When self-hosting:

- **Full Control**: Complete control over hardware, networking, and configurations
- **Custom Integrations**: Ability to integrate with existing infrastructure and tools
- **Data Localization**: Maximum data security for high-compliance environments
- **Custom Resource Allocation**: Optimize for your specific performance requirements
- **Custom Scaling**: Implement your own scaling strategies and resource management

Best for: Organizations with specific infrastructure, security compliance requirements.