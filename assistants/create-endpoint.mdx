---
title: "Creating an Endpoint"
description: "Step-by-step guide to creating a new AI endpoint"
sidebarTitle: "Create Endpoint"
---

This guide walks you through the process of creating a new endpoint in the platform.

<Steps>
<Step title="Navigate to Endpoints">
![Navigate to Endpoints](/images/create_assistant/create_endpoint_1.png)

Begin by navigating to the Endpoints section under Deployments in the main navigation menu.

</Step>

<Step title="Initiate Endpoint Creation">
![Initiate Endpoint Creation](/images/create_assistant/create_endpoint_2.png)

Click on the "Create new endpoint" button to start the process of creating a new endpoint.

</Step>

<Step title="Choose Model and Configure Instructions">
![Choose Model and Configure Instructions](/images/create_assistant/create_endpoint_3.png)

In the form:

- Select your preferred LLM (Language Learning Model) from the dropdown menu
- Enter the system instructions for your endpoint
- Note that instructions can accept parameters in Jinja2 format
- The parameter "messages" is reserved and will be available via the assistant conversation

```txt Sample System Prompt
# AI Summarizer System Instructions

## Configuration
- You are an AI summarizer.
- Return exactly one JSON object with specific keys.
- Process conversation transcripts into structured summaries.

## Output Format
- JSON object with required keys:
  - [title](string): Brief descriptive title for the conversation
  - [summary](string): Concise summary of the content


## Example Output
{
  "title": "client negotiation practice",
  "summary": "summary"
}

```

</Step>

<Step title="Add User Prompts">
![Add User Prompts](/images/create_assistant/create_endpoint_4.png)

You can add additional user prompts:

- Click the "Add new message" button to include user messages
- These prompts help define how the endpoint will interact with users
- Configure multiple prompts to create more sophisticated conversation flows
  </Step>

<Step title="Configure Advanced Options">
![Configure Advanced Options](/images/create_assistant/create_endpoint_5.png)

Access advanced configuration options:

- Click the settings icon near the LLM choice
- Adjust parameters like:
  - Frequency Penalty
  - Temperature
  - Top P
  - Presence Penalty
  - Max Completion Tokens
  - Response Format
  - Stop Sequences
  - Metadata
  - User Identifier
  - Tool Choices

These settings allow you to fine-tune your endpoint's performance and behavior.

For example, you can set a JSON response format to enforce structured output:

```json Response Format
{
  "type": "json_schema",
  "json_schema": {
    "name": "summarize",
    "schema": {
      "type": "object",
      "properties": {
        "title": { "type": "string" },
        "summary": { "type": "string" }
      },
      "required": ["title", "summary"],
      "additionalProperties": false
    },
    "strict": true
  }
}
```

</Step>

<Step title="Define Endpoint Profile">
After configuring your endpoint's behavior, define its profile:
- Provide a descriptive name
- Add a brief description
- Include relevant tags for organizational purposes

Click "Create Endpoint" when done.

Please note that new versions of the endpoint will not be deployed automatically. Manual deployment will be required to update the production version.

</Step>
</Steps>

Once deployed, your endpoint will be available for integration with your applications. For more information on how to use your endpoint with assistants, refer to the [Creating an Assistant](/assistants/create-assistant) guide.
